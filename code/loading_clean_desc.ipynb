{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import hashlib\n",
    "import dask.dataframe as dd\n",
    "import ssl\n",
    "import nltk\n",
    "import string\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "path_parent_directory = os.path.dirname(current_directory)\n",
    "master_data_file = os.path.join(path_parent_directory, 'data', 'master_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes ~20 seconds to read the csv with 7M rows; memory usage is ~1.2 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_56939/1469784892.py:2: DtypeWarning: Columns (2,5,8,10,11,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_master_data = pd.read_csv(master_data_file, sep = ',', encoding = 'utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7147355 entries, 0 to 7147354\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   BUILDING_PERMIT_ID           object \n",
      " 1   PROPERTY_ID                  object \n",
      " 2   CONTRACTOR_ID                object \n",
      " 3   EFFECTIVE_DATE               object \n",
      " 4   JOB_VALUE                    float64\n",
      " 5   PERMIT_NUMBER                object \n",
      " 6   STATUS                       object \n",
      " 7   DESCRIPTION                  object \n",
      " 8   PROJECT_NAME                 object \n",
      " 9   TYPE                         object \n",
      " 10  SUBTYPE                      object \n",
      " 11  BUSINESS_NAME                object \n",
      " 12  HOMEOWNER_NAME               object \n",
      " 13  STATE                        object \n",
      " 14  ZIP_CODE                     float64\n",
      " 15  CITY                         object \n",
      " 16  PROJECT_TYPE                 object \n",
      " 17  PERMIT_STATUS                object \n",
      " 18  representative_builder_name  object \n",
      " 19  false_positive               float64\n",
      " 20  true_positive                float64\n",
      " 21  identified_business_name     float64\n",
      "dtypes: float64(5), object(17)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "# Loading csv into dataframe\n",
    "df_master_data = pd.read_csv(master_data_file, sep = ',', encoding = 'utf-8')\n",
    "\n",
    "# Get dataset characteristics \n",
    "df_master_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BUILDING_PERMIT_ID', 'PROPERTY_ID', 'EFFECTIVE_DATE', 'DESCRIPTION',\n",
       "       'BUSINESS_NAME', 'HOMEOWNER_NAME', 'STATE', 'ZIP_CODE', 'CITY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scope definition: first, we keep only relevant columns\n",
    "cols_to_keep = ['BUILDING_PERMIT_ID', 'PROPERTY_ID', 'EFFECTIVE_DATE', 'DESCRIPTION','BUSINESS_NAME', 'HOMEOWNER_NAME', 'STATE', 'ZIP_CODE', 'CITY']\n",
    "\n",
    "# Keep only relevant columns\n",
    "df_master_data = df_master_data[cols_to_keep]\n",
    "df_master_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6574318 entries, 0 to 7147354\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   BUILDING_PERMIT_ID  object \n",
      " 1   PROPERTY_ID         object \n",
      " 2   EFFECTIVE_DATE      object \n",
      " 3   DESCRIPTION         object \n",
      " 4   BUSINESS_NAME       object \n",
      " 5   HOMEOWNER_NAME      object \n",
      " 6   STATE               object \n",
      " 7   ZIP_CODE            float64\n",
      " 8   CITY                object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 501.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Scope definition: we remove any rows with blank descriptions\n",
    "df_master_data = df_master_data.dropna(subset = ['DESCRIPTION'])\n",
    "df_master_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling descriptions\n",
    "* We first assign IDs to descriptions and check how many unique values exist \n",
    "* Then, we extract the unique descriptions in a new dataframe and add a column called 'clean_description', which will contain the cleaned version of the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original method time: 1.88 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_56939/1423126111.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_descrip_factorize['DESCRIPTION_ID'] = df_descrip_factorize['DESCRIPTION'].factorize()[0]\n"
     ]
    }
   ],
   "source": [
    "# Assigning unique descriptions - checking how much time it takes for a given method\n",
    "\n",
    "# Original method\n",
    "def original_method(df):\n",
    "    df_descrip_factorize = df[['DESCRIPTION']]\n",
    "    df_descrip_factorize['DESCRIPTION_ID'] = df_descrip_factorize['DESCRIPTION'].factorize()[0]\n",
    "\n",
    "# Time the original method\n",
    "original_time = timeit.timeit(lambda: original_method(df_master_data), number=1)\n",
    "print(f\"Original method time: {original_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6574318 entries, 0 to 7147354\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   BUILDING_PERMIT_ID  object \n",
      " 1   PROPERTY_ID         object \n",
      " 2   EFFECTIVE_DATE      object \n",
      " 3   DESCRIPTION         object \n",
      " 4   BUSINESS_NAME       object \n",
      " 5   HOMEOWNER_NAME      object \n",
      " 6   STATE               object \n",
      " 7   ZIP_CODE            float64\n",
      " 8   CITY                object \n",
      " 9   DESCRIPTION_ID      int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 551.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Applying the factorize method\n",
    "df_master_data['DESCRIPTION_ID'] = df_master_data['DESCRIPTION'].factorize()[0]\n",
    "df_master_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1573664 entries, 0 to 7147339\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   DESCRIPTION     1573664 non-null  object\n",
      " 1   DESCRIPTION_ID  1573664 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 36.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Extracting descriptions and IDs\n",
    "cols_to_keep = ['DESCRIPTION', 'DESCRIPTION_ID']\n",
    "\n",
    "# Keep only relevant columns and removing duplicates\n",
    "df_master_desc_w_id = df_master_data[cols_to_keep]\n",
    "df_master_desc_w_id = df_master_desc_w_id.drop_duplicates()\n",
    "df_master_desc_w_id.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary step - save csv to inspect\n",
    "# df_master_desc_w_id.to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/eshan23/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning descriptions\n",
    "# Now that we have all descriptions, we can clean them and create a mapping of unclean-clean descriptions\n",
    "\n",
    "# Function to clean a name \n",
    "def get_clean_name_stop_words(name):\n",
    "    '''\n",
    "    This function takes an unclean name as an input, converts it to lower case, removes punctuations, numerals, and stop words\n",
    "    Returns the cleaned name \n",
    "    '''\n",
    "    name = name.lower()\n",
    "    translation_table = str.maketrans('', '', string.punctuation)\n",
    "    name = name.translate(translation_table)\n",
    "\n",
    "    # Remove stop words\n",
    "    cleaned_name = ' '.join(word for word in name.split() if word not in nltk_stop_words)\n",
    "    return cleaned_name\n",
    "\n",
    "# Function to map clean name with unclean name in a dataframe \n",
    "def get_clean_name_mapping(dataframe, col = None, clean_col_name= None):\n",
    "\n",
    "    '''\n",
    "    Inputs: dataframe which has the unclean name, col = name of unclean column,\\\n",
    "            clean_col_name: the name we want to assign our clean_column\n",
    "    Process:Drop na values, apply cleaning function defined above, map unclean and clean names, filter for NAs and \\\n",
    "            drop duplicate rows. Dropping duplicate rows will help optimize our name-matching algorithm\\\n",
    "            Since our final step of reconciliation will involve joining on clean names, we do not risk losing any rows\n",
    "    Output: dataframe with mapping of unclean name with clean name \n",
    "    '''\n",
    "    output_df = dataframe.copy()\n",
    "    unique_names = output_df[col].dropna()\n",
    "    clean_names = [get_clean_name_stop_words(name) for name in unique_names]\n",
    "    name_mapping = dict(zip(unique_names, clean_names))\n",
    "    output_df.loc[:,clean_col_name] = output_df.loc[:,col].map(name_mapping)\n",
    "    #output_df = output_df[output_df[clean_col_name].notna() & (output_df[clean_col_name] != '')]  # We will keep 'NA' / blank rows too. \n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "# Importing NLTK stopwords for cleaning names\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the stopwords\n",
    "nltk_stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning ~1.5M descriptions takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1573664 entries, 0 to 7147339\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count    Dtype \n",
      "---  ------             --------------    ----- \n",
      " 0   DESCRIPTION        1573664 non-null  object\n",
      " 1   DESCRIPTION_ID     1573664 non-null  int64 \n",
      " 2   CLEAN_DESCRIPTION  1573664 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 48.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>DESCRIPTION_ID</th>\n",
       "      <th>CLEAN_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New attached solar heating green house</td>\n",
       "      <td>0</td>\n",
       "      <td>new attached solar heating green house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New attached solar heating greenhouse</td>\n",
       "      <td>1</td>\n",
       "      <td>new attached solar heating greenhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addition of a family w/solar glass</td>\n",
       "      <td>2</td>\n",
       "      <td>addition family wsolar glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Freestanding solar greenhouse</td>\n",
       "      <td>3</td>\n",
       "      <td>freestanding solar greenhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Addition of a solar sun space</td>\n",
       "      <td>4</td>\n",
       "      <td>addition solar sun space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              DESCRIPTION  DESCRIPTION_ID  \\\n",
       "0  New attached solar heating green house               0   \n",
       "2   New attached solar heating greenhouse               1   \n",
       "4      Addition of a family w/solar glass               2   \n",
       "6           Freestanding solar greenhouse               3   \n",
       "7           Addition of a solar sun space               4   \n",
       "\n",
       "                        CLEAN_DESCRIPTION  \n",
       "0  new attached solar heating green house  \n",
       "2   new attached solar heating greenhouse  \n",
       "4            addition family wsolar glass  \n",
       "6           freestanding solar greenhouse  \n",
       "7                addition solar sun space  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning descriptions\n",
    "df_master_desc_w_id_clean = get_clean_name_mapping(df_master_desc_w_id, 'DESCRIPTION', 'CLEAN_DESCRIPTION')\n",
    "df_master_desc_w_id_clean.info()\n",
    "df_master_desc_w_id_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading to examine\n",
    "# df_master_desc_w_id_clean.to_csv(\"sample_v1.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through manual inspection, we can see that some descriptions are blanks or have only numeric values. Let's label them \"junk\" before attempting to label rooftop_solar 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling junk descriptions\n",
    "# We will label junk = 1 as those which either have only numerals or are less than 5 characters long (including blanks)\n",
    "\n",
    "# Function to label junk descriptions\n",
    "def label_junk_descriptions(dataframe, col = None, junk_label = None):\n",
    "    '''\n",
    "    Inputs: dataframe which has the unclean name, col = name of unclean column,\\\n",
    "            junk_label: the label we want to assign to junk names\n",
    "    Process: Label junk descriptions as those which either have only numerals or are less than 5 characters long (including blanks)\n",
    "    Output: dataframe with junk descriptions labeled\n",
    "    '''\n",
    "    output_df = dataframe.copy()\n",
    "    output_df.loc[:,junk_label] = np.where((output_df[col].str.isnumeric()) | (output_df[col].str.len() < 5), 1, 0)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label junk descriptions\n",
    "df_master_desc_w_id_clean = label_junk_descriptions(df_master_desc_w_id_clean, 'CLEAN_DESCRIPTION', 'junk')\n",
    "# Examined output manually to check it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leetcode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
